{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  3.4.1 神经网络的构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "  def __init__(self, **kwargs):\n",
    "    super(MLP, self).__init__()\n",
    "    self.hidden = nn.Linear(784, 256)\n",
    "    self.act = nn.ReLU()\n",
    "    self.output = nn.Linear(256, 10)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    a = self.act(self.hidden(x))\n",
    "    return self.output(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (act): ReLU()\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0658,  0.1477,  0.0087, -0.1591, -0.0906,  0.1742,  0.0189,  0.1231,\n",
       "          0.0275, -0.0591],\n",
       "        [-0.0126,  0.0261,  0.0054, -0.0588, -0.0947,  0.1191,  0.0598, -0.0363,\n",
       "          0.1346, -0.0306]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(2, 784)\n",
    "net = MLP()\n",
    "print(net)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 神经网络中常见的层\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 不含模型参数的层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MyLayer(nn.Module):\n",
    "  def __init__(self, **kwargs):\n",
    "    super(MyLayer, self).__init__(**kwargs)\n",
    "  def forward(self, x):\n",
    "    return x - x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = MyLayer()\n",
    "layer(torch.tensor([1, 2, 3, 4, 5], dtype=torch.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 含模型参数的层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyListDense(\n",
      "  (params): ParameterList(\n",
      "      (0): Parameter containing: [torch.float32 of size 4x4]\n",
      "      (1): Parameter containing: [torch.float32 of size 4x4]\n",
      "      (2): Parameter containing: [torch.float32 of size 4x4]\n",
      "      (3): Parameter containing: [torch.float32 of size 4x1]\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-70.6800],\n",
       "        [  8.7415],\n",
       "        [ -3.3696],\n",
       "        [ -0.9187]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyListDense(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MyListDense, self).__init__()\n",
    "    self.params = nn.ParameterList([nn.Parameter(torch.randn(4, 4)) for i in range(3)])\n",
    "    self.params.append(nn.Parameter(torch.randn(4, 1)))\n",
    "    \n",
    "  def forward(self, x):\n",
    "    for i in range(len(self.params)):\n",
    "      x = torch.mm(x, self.params[i])\n",
    "    return x\n",
    "  \n",
    "net = MyListDense()\n",
    "print(net)\n",
    "net(torch.randn(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyDictDense(\n",
      "  (params): ParameterDict(\n",
      "      (linear1): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (linear2): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (linear3): Parameter containing: [torch.FloatTensor of size 4x1]\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2645],\n",
       "        [ 1.2620],\n",
       "        [ 3.0418],\n",
       "        [-0.0383]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyDictDense(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MyDictDense, self).__init__()\n",
    "    self.params = nn.ParameterDict({\n",
    "      'linear1': nn.Parameter(torch.randn(4, 4)),\n",
    "      'linear2': nn.Parameter(torch.randn(4, 4)),\n",
    "    })\n",
    "    self.params.update({'linear3': nn.Parameter(torch.randn(4, 1))})\n",
    "  \n",
    "  def forward(self, x, choice='linear1'):\n",
    "    return torch.mm(x, self.params[choice])\n",
    "  \n",
    "net = MyDictDense()\n",
    "print(net)\n",
    "net(torch.randn(4,4), \"linear3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 二维卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def corr2d(X, K):\n",
    "  h, w = K.shape\n",
    "  X, K = X.float(), K.float()\n",
    "  Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "  for i in range(Y.shape[0]):\n",
    "    for j in range(Y.shape[1]):\n",
    "      Y[i, j] = (X[i:i+h, j:j+w] * K).sum()\n",
    "  return Y\n",
    "\n",
    "class Conv2D(nn.Module):\n",
    "  def __init__(self, kernel_size):\n",
    "    super(Conv2D, self).__init__()\n",
    "    self.weight = nn.Parameter(torch.randn(kernel_size))\n",
    "    self.bias = nn.Parameter(torch.randn(1))\n",
    "    \n",
    "  def forward(self, x):\n",
    "    return corr2d(x, self.weight) + self.bias\n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nngen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
